{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file 'debate_truthfulqa.json' has been created.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "MODEL_LIST = [\n",
    "    \"openai/chatgpt-4o-latest\",\n",
    "    \"google/gemini-2.0-flash-001\",\n",
    "    \"google/gemini-2.0-flash-lite-001\",\n",
    "    \"google/gemini-flash-1.5\",\n",
    "    \"meta-llama/llama-3.3-70b-instruct\",\n",
    "    \"anthropic/claude-3.5-haiku\",\n",
    "    \"google/gemma-2-27b-it\",\n",
    "    \"meta-llama/llama-3-70b-instruct\",\n",
    "    \"google/gemma-2-9b-it\",\n",
    "    \"qwen/qwen-2-72b-instruct\",\n",
    "    \"meta-llama/llama-3.1-8b-instruct\",\n",
    "    \"meta-llama/llama-3-8b-instruct\",\n",
    "    \"google/gemini-pro\",\n",
    "    \"meta-llama/llama-3.2-3b-instruct\"\n",
    "]\n",
    "\n",
    "MODEL_NAME_ONLY = [MODEL.split(\"/\")[-1] for MODEL in MODEL_LIST]\n",
    "\n",
    "n_models = len(MODEL_LIST)\n",
    "\n",
    "data_id = \"truthfulqa\"\n",
    "\n",
    "# Initialize matrices for correctness ratios and total evaluations\n",
    "correctness_matrix = np.zeros((n_models, n_models))\n",
    "total_matrix = np.zeros((n_models, n_models))\n",
    "\n",
    "# Process each debater-judge pairing\n",
    "for i, model_debater in enumerate(MODEL_LIST):\n",
    "    for j, model_judge in enumerate(MODEL_LIST):\n",
    "        correct_cnt = 0\n",
    "        total_cnt = 0\n",
    "        for data_idx in range(20):\n",
    "            filename = f\"./DEBATE_DATA_{data_id}/judge_{data_idx}_{model_debater.split('/')[-1]}_{model_judge.split('/')[-1]}.txt\"\n",
    "            if not os.path.exists(filename):\n",
    "                continue\n",
    "\n",
    "            with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "                judge_response = f.read()\n",
    "\n",
    "            total_cnt += 1\n",
    "            # Check for answer \"1\"\n",
    "            if (\n",
    "                \"Answer: 1\" in judge_response or \"Answer: <1>\" in judge_response\n",
    "                or \"**Answer**: 1\" in judge_response or \"**Answer**: <1>\" in judge_response\n",
    "            ):\n",
    "                if data_idx % 2 == 1:\n",
    "                    correct_cnt += 1\n",
    "                    \n",
    "            # Check for answer \"2\"\n",
    "            elif (\n",
    "                \"Answer: 2\" in judge_response or \"Answer: <2>\" in judge_response\n",
    "                or \"**Answer**: 2\" in judge_response or \"**Answer**: <2>\" in judge_response\n",
    "            ):\n",
    "                if data_idx % 2 == 0:  # \"2\" is correct for even indices\n",
    "                    correct_cnt += 1\n",
    "#        print(f\"{model_debater} vs {model_judge}, {correct_cnt}/{total_cnt}\")\n",
    "        \n",
    "        if total_cnt > 0:\n",
    "            correctness_matrix[i, j] = correct_cnt / total_cnt\n",
    "            total_matrix[i, j] = total_cnt\n",
    "        else:\n",
    "            correctness_matrix[i, j] = 0.0\n",
    "            total_matrix[i, j] = 0\n",
    "\n",
    "# -------------------------------\n",
    "# JSON Output Section: For a fixed judge model\n",
    "# -------------------------------\n",
    "\n",
    "results = []\n",
    "for i, model_debater in enumerate(MODEL_LIST):\n",
    "    for j, model_judge in enumerate(MODEL_LIST):\n",
    "        result = {\n",
    "            \"guard\": model_judge,\n",
    "            \"houdini\": model_debater,\n",
    "            \"guard_win_prob\": correctness_matrix[i, j],\n",
    "            \"total_games\": total_matrix[i, j],\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "# Write the JSON data to a file\n",
    "with open(f\"debate_{data_id}.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(results, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON file 'debate_{data_id}.json' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file 'debate_quality.json' has been created.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "MODEL_LIST = [\n",
    "    \"openai/chatgpt-4o-latest\",\n",
    "    \"google/gemini-2.0-flash-001\",\n",
    "    \"google/gemini-2.0-flash-lite-001\",\n",
    "    \"google/gemini-flash-1.5\",\n",
    "    \"meta-llama/llama-3.3-70b-instruct\",\n",
    "    \"anthropic/claude-3.5-haiku\",\n",
    "    \"google/gemma-2-27b-it\",\n",
    "    \"meta-llama/llama-3-70b-instruct\",\n",
    "    \"google/gemma-2-9b-it\",\n",
    "    \"qwen/qwen-2-72b-instruct\",\n",
    "    \"meta-llama/llama-3.1-8b-instruct\",\n",
    "    \"meta-llama/llama-3-8b-instruct\",\n",
    "    \"google/gemini-pro\",\n",
    "    \"meta-llama/llama-3.2-3b-instruct\"\n",
    "]\n",
    "\n",
    "MODEL_NAME_ONLY = [MODEL.split(\"/\")[-1] for MODEL in MODEL_LIST]\n",
    "\n",
    "n_models = len(MODEL_LIST)\n",
    "\n",
    "data_id = \"quality\"\n",
    "\n",
    "# Initialize matrices for correctness ratios and total evaluations\n",
    "correctness_matrix = np.zeros((n_models, n_models))\n",
    "total_matrix = np.zeros((n_models, n_models))\n",
    "\n",
    "# Process each debater-judge pairing\n",
    "for i, model_debater in enumerate(MODEL_LIST):\n",
    "    for j, model_judge in enumerate(MODEL_LIST):\n",
    "        correct_cnt = 0\n",
    "        total_cnt = 0\n",
    "        for data_idx in range(20):\n",
    "            filename = f\"./DEBATE_DATA_{data_id}/{model_debater.split('/')[-1]}_{data_idx}_{model_judge.split('/')[-1]}_judge_response.dat\"\n",
    "            if not os.path.exists(filename):\n",
    "                continue\n",
    "\n",
    "            with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "                judge_response = f.read()\n",
    "\n",
    "            total_cnt += 1\n",
    "            # Check for answer \"1\"\n",
    "            if (\n",
    "                \"Answer: 1\" in judge_response or \"Answer: <1>\" in judge_response\n",
    "                or \"**Answer**: 1\" in judge_response or \"**Answer**: <1>\" in judge_response\n",
    "            ):\n",
    "                if data_idx % 2 == 1:\n",
    "                    correct_cnt += 1\n",
    "                    \n",
    "            # Check for answer \"2\"\n",
    "            elif (\n",
    "                \"Answer: 2\" in judge_response or \"Answer: <2>\" in judge_response\n",
    "                or \"**Answer**: 2\" in judge_response or \"**Answer**: <2>\" in judge_response\n",
    "            ):\n",
    "                if data_idx % 2 == 0:  # \"2\" is correct for even indices\n",
    "                    correct_cnt += 1\n",
    "        \n",
    "        if total_cnt > 0:\n",
    "            correctness_matrix[i, j] = correct_cnt / total_cnt\n",
    "            total_matrix[i, j] = total_cnt\n",
    "        else:\n",
    "            correctness_matrix[i, j] = 0.0\n",
    "            total_matrix[i, j] = 0\n",
    "\n",
    "# -------------------------------\n",
    "# JSON Output Section: For a fixed judge model\n",
    "# -------------------------------\n",
    "\n",
    "results = []\n",
    "for i, model_debater in enumerate(MODEL_LIST):\n",
    "    for j, model_judge in enumerate(MODEL_LIST):\n",
    "        result = {\n",
    "            \"guard\": model_judge,\n",
    "            \"houdini\": model_debater,\n",
    "            \"guard_win_prob\": correctness_matrix[i, j],\n",
    "            \"total_games\": total_matrix[i, j],\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "# Write the JSON data to a file\n",
    "with open(f\"debate_{data_id}.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(results, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON file 'debate_{data_id}.json' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "graph"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
